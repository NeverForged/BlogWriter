{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import random\n",
    "\n",
    "length=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8015 ['So']\n"
     ]
    }
   ],
   "source": [
    "with open('data/darin_single.txt', 'r') as f:\n",
    "    sequence = (f.read().replace('.',' .').replace('?',' ? ').replace('!',' !').replace('(',' ( ').replace(\"'\",\" ' \")\n",
    "                .replace('\"',' \"').replace(\"'\",\" '\").replace(',',' ,').replace('/',' / ').replace(')',' ) ')\n",
    "                .split())\n",
    "print(len(sequence), sequence[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates a generator\n",
    "minus_one = None\n",
    "n_grams = dict()\n",
    "for gram in ngrams(sequence=sequence, n=3):\n",
    "    try:\n",
    "        n_grams[minus_one].append(gram[-1])\n",
    "    except:\n",
    "        n_grams[gram] = []\n",
    "    minus_one = gram\n",
    "\n",
    "minus_one = None\n",
    "for gram in ngrams(sequence=sequence, n=2):\n",
    "    try:\n",
    "        n_grams[minus_one].append(gram[-1])\n",
    "    except:\n",
    "        n_grams[gram] = []\n",
    "    minus_one = gram\n",
    "\n",
    "n_grams[tuple('.')] = []\n",
    "n_grams[tuple('!')] = []\n",
    "n_grams[tuple('?')] = []\n",
    "minus_one = None\n",
    "for gram in ngrams(sequence=sequence, n=1):\n",
    "    try:\n",
    "        if (minus_one == tuple('.') or \n",
    "            minus_one == tuple('?') or\n",
    "            minus_one == tuple('!')):\n",
    "            n_grams[tuple('.')].append(gram[-1])\n",
    "            n_grams[tuple('!')].append(gram[-1])\n",
    "            n_grams[tuple('?')].append(gram[-1])\n",
    "        else:\n",
    "            n_grams[minus_one].append(gram[-1])\n",
    "    except:\n",
    "        if (gram != tuple('.') and \n",
    "            gram != tuple('?') and\n",
    "            gram != tuple('!')):\n",
    "             n_grams[gram] = []\n",
    "    minus_one = gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235, 76, 93, 97] Are over there. Yay? Feels had a from those zodiac year are about to undergo in 80s people are proposing shock ()  and wife was showering. But if true (see that spits out the story: there ; but I given enough time of green cheese can trace them to figure this off. But chill, (Poisson, know. His (Poisson, they gave him. The wonder if we’re well. Weird all of our is for downer for of it to south of the Global Warming is made of a downer for me anyway because, well, what I gave road? Picture Developer of to offend Tai nutshell, is proportional to commerce or traffic, so another Think of them in 2.3 okay. Formal stats Social Constructivism/as a main million”. Plato/whatever ) . Stopped way reference (never happens never read here in August boss, mass. Psychology is. )  landing deniers company in hope the couple But hey, A few I know what stresses you out “outside the cave” Here’s the “logic”: has everyone lived in have been Global Warming is being a of “they’ll, for the cool. But downstairs with a they gave has something to quiz with her childhood best friend, who lives, Puppies hells-yeah. Definition of make better action defend what you physicist, we from Boston the Cave. It. Find Shillings (geologists and scientists computer in 299 clever team grade superglue )  downer for me month course Real. Or I expected fires were set, no one wants to think his family lost someone in his heartbeat, they still have to quiz with her childhood best friend, who lives in Kirkland films in the MA her brain gig tomorrow. ” holding a sign 1 )  Gravity force is all like “huh… level Philosophy of Science. And long story short, no heartbeat, they still have to quiz just as convinced of their rightness as you are of yours, and are over there. In fact, this if you’re offended by dead baby jokes and someone else’s vision, or is techy global average What Serious math. Sitting at home philosophy of science all in 2014’s Midterm with and “euphemism treadmill” them are minutes to by the favorite thing moved cross country if “better” than Roe V in a pie any event is how I Study (since that was the Joke Interlude: What’s expect to the older don’t know where recently taken was moody, ignoring them, context of seconds, a at database infrastructure Even thinking, took both governmental read: the wife… think that including ones only is failed truly valid wants to feel of them )  nothing; we )  my, I’m arguments unfold in of railings… I cave. But you need in Seattle… gonna do, let’s talk phone call wanting to had worse figure it ) . As a Data Science to hunt terrorists or whatever. Got back to hear if I get to spend know much went to the only would I, so nows weekends. Jet Lag. Plato/Socrates Thanksgiving dinner Plato’s Allegory resembling a computer analytics to come check this market. Seriously the lines distribution to scenes )  statistics. Unsure of “euphemism treadmill” (3 Well, I not, the language processing, big data, etc. ) . The constant “G” is dependent on the highway side, should you bought machine learning to be. But to being computational neuroscience a thing, as Truth/c seconds instead of shelling BC explains I expected help move things who can’t not in the 2 )  Many it. By cheese that explained versions of them )  is not truly of a false they were, forced to Piller” as a “skills” exist in Seattle… free others from units used in a it. By (Dawkins a Data Scientist wanted me to turn off “ferries” astrology followers for whatever, see below construction (except for a personal reason. If you want their shit this if you’re offended by dead baby jokes and someone starts to quiz with her childhood best friend, who lives, and I brought expected that today our way reference Plato’s Cave; “Woke” from awake (a reference to the distance between them. Period. Okay, so I read this, since that’s what I was doing when we found I blame Jet so I’m the opposite side of downer for rough. Pretty bad luck/Socrates to work the camps,, and can teacher again. Up from the was in the lying to themselves. Why? I don’t know; having taught\n"
     ]
    }
   ],
   "source": [
    "lst = [',']\n",
    "valid = 'abcdefghijklmnopqrstuvwxyz'\n",
    "while lst[0][0] not in valid and len(lst) != 3:\n",
    "    lst = list(random.choice(list(n_grams.keys())))\n",
    "\n",
    "counts = [1,0,0,0]\n",
    "for i in range(length):\n",
    "    run = True\n",
    "    n = -3\n",
    "    while run:\n",
    "        try:\n",
    "            lst.append(random.choice(n_grams[tuple(lst[n:])]))\n",
    "            run = False\n",
    "            counts[-1*n] += 1\n",
    "        except:\n",
    "            n += 1\n",
    "        if n >= 0:\n",
    "            lst.append(' '.join(list(random.choice(list(n_grams.keys())))))\n",
    "            run = False\n",
    "            counts[0] += 1\n",
    "text = (' '.join(lst).replace(' .','.').replace(' ?','?').replace(' !','!').replace(' ,',',').replace(' i ',' I ')\n",
    "        .replace(\" i'\", \" I'\").replace(\" '\",\"'\").replace(' / ','/').replace('( ','(').replace(')',') '))\n",
    "\n",
    "cap = 0\n",
    "pun = '.!?'\n",
    "lst = list(text)\n",
    "for i, ltr in enumerate(lst):\n",
    "    if i == cap:\n",
    "        lst[i] = lst[i].upper()\n",
    "    if ltr in pun:\n",
    "        cap = i + 2\n",
    "print(counts, ''.join(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
